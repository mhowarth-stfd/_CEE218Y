---
title: "AMW_AirPollution"
author: "Awoenam Mauna-Woanya"
date: "3/7/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(sf)
library(leaflet)
library(mapview)
library(censusapi)
library(jsonlite)
library(mapboxapi)
library(tigris)


path <- "C:/Users/mouse/OneDrive - Stanford/MS2/WinterQ/218Y/Hazards/"

# insert your G drive path here
path_data <- "G:/My Drive/218Y/Assignments/5A/data/"
```

create JSON file from URL and load all purple air sensors w spatial data
```{r}

pa_api <- "5C40A667-99B3-11EC-B9BF-42010A800003"

# read in JSON file 
json <- fromJSON(paste0(
  "https://api.purpleair.com/v1/sensors?api_key=",
  pa_api,
  "&fields=name,location_type,latitude,longitude,pm2.5_1week,temperature,humidity,primary_id_a,primary_key_a,secondary_id_a,secondary_key_a,primary_id_b,primary_key_b,secondary_id_b,secondary_key_b"
))

all_senors <- json %>% 
  
  # grab data from JSON
  .$data %>% 
  as.data.frame() %>% 
  
  # rename columns with original names
  set_names(json$fields) %>% 
  filter(
    !is.na(longitude),
    !is.na(latitude)
  ) %>% 
  
  # adding geometry based on lat/long
  st_as_sf(coords = c("longitude", "latitude"),
           crs = 4326) %>% 
  mutate(location_type = ifelse(
    location_type == 0, 
    "outside", 
    "inside"
  ))


```

Bay Area specific sensors
```{r}
bay_county_names <-
  c(
    "belmont",
    "Contra Costa",
    "Marin",
    "Napa",
    "San Francisco",
    "San Mateo",
    "Santa Clara",
    "Solano",
    "Sonoma"
  )

bay_counties <- 
  counties("CA", cb = T, progress_bar = F) %>% 
  filter(NAME %in% bay_county_names) %>% 
  st_transform(4326)

bay_sensors <- 
  all_senors %>% 
  .[bay_counties, ]


```

Convert raw data from sensors to AQI

```{r}
bay_sensors_clean <- bay_sensors %>% 
  filter(
    !is.na(pm2.5_1week),
    !is.na(humidity)
  ) %>% 
  
  # PM2.5 to AQI, then labeling AQI
  mutate(
    PM25 = 0.524*as.numeric(pm2.5_1week) - 0.0852*as.numeric(humidity) + 5.72,
    AQI = case_when(
      PM25 <= 12 ~ 
        paste(round(50/12*PM25), "Good"),
      PM25 <= 35.4 ~ 
        paste(round((100-51)/(35.4-12)*(PM25 - 12) + 51), "Moderate"),
      PM25 <= 55.4 ~
        paste(round((150-101)/(55.4-35.4)*(PM25 - 35.4) + 101), "Moderately Unhealthy"),
      PM25 <= 150.4 ~
        paste(round((200-151)/(150.4-55.4)*(PM25 - 55.4) + 151), "Unhealthy"),
      PM25 <= 250.4 ~
        paste(round((300-201)/(250.4-150.4)*(PM25 - 150.4) + 201), "Very Unhealthy"),
      TRUE ~ 
        paste(round((500-301)/(500.4-250.5)*(PM25 - 250.5) + 301), "Hazardous")
    )
  ) %>% 
  
  # separate AQI into value and category
  separate(
    AQI, 
    into = c("AQI", "AQI_Cat"), 
    sep = " ",
    extra = "merge"
  ) %>% 
  mutate(
    AQI = as.numeric(AQI),
    AQI_Cat = AQI_Cat %>% 
      factor(levels = c("Good", "Moderate", "Moderately Unhealthy", "Unhealthy", "Very Unhealthy", "Hazardous")
  ))
```

Visualize outdoor sensors using colorFactor()

```{r}
aqi_pal <- colorFactor(
  palette = "RdYlGn",
  reverse = T,
  domain = bay_sensors_clean$AQI_Cat
)

bay_sensors_clean %>% 
  filter(location_type == "outside") %>% 
  leaflet() %>% 
  addProviderTiles(
    provider = providers$CartoDB.Positron
  ) %>% 
  addCircleMarkers(
    color = ~aqi_pal(AQI_Cat),
    label = ~AQI_Cat,
    radius = 5, # circle marker size
    opacity =  .75
  ) %>% 
  addLegend(
    pal = aqi_pal,
    values = ~AQI_Cat
  )

```

Using colorQuantile() to highlight differences

```{r}
aqi_pal2 <- colorQuantile(
  palette = "RdYlGn",
  reverse = T, 
  domain = bay_sensors_clean$AQI, 
  n = 5 # bins
)

bay_sensors_clean %>% 
  leaflet() %>% 
  addProviderTiles(
    provider = providers$CartoDB.Positron
  ) %>% 
  addCircleMarkers(
    color = ~aqi_pal2(AQI),
    label = ~paste0(AQI, ", ", AQI_Cat), 
    radius = 5, 
    opacity = .75
  ) %>% 
  addLegend(
    pal = aqi_pal2,
    values = ~AQI
  )
  
  
  
```


Interpolating areas without sensors with Voronoi polygons
```{r}
bay_pm25_voronoi <- 
  bay_sensors_clean %>% 
  filter(location_type == "outside") %>% 
  st_union() %>% 
  st_voronoi() %>% 
  
  # voronoi turns from sf to regular object so we turn it back
  st_cast() %>% st_as_sf() %>% 
  st_intersection(., st_union(bay_counties)) %>% 
  
  # join back to original purple air points
  st_join(bay_sensors_clean %>% filter(location_type == "outside"))

ggplot(bay_pm25_voronoi) +
  geom_sf()
```
Focusing on SF
```{r}
# grab SF CBGs
sf_cbgs <- block_groups("CA", "San Francisco", cb = T, progress_bar = F) %>% 
  st_transform(4326)

sf_pm25_voronoi_cbg <- 
  bay_pm25_voronoi %>% 
  st_intersection(sf_cbgs) %>% 
  st_make_valid() %>% 
  mutate(
    area = st_area(.) %>% as.numeric()
  ) %>% 
  st_drop_geometry() %>% 
  group_by(GEOID) %>% 
  summarize(
    PM25 = weighted.mean(PM25, area, na.rm = T)
  ) %>% 
  left_join(sf_cbgs %>% dplyr::select(GEOID)) %>% 
  st_as_sf()

saveRDS(sf_pm25_voronoi_cbg, paste0(path,"sf_pm25_voronoi_cbg.rds"))

sf_pm25_voronoi_cbg <- readRDS(paste0(path, "sf_pm25_voronoi_cbg.rds"))
  
```

Mapping CBG results + PurpleAir data

```{r}
sf_sensors <- 
  bay_sensors_clean %>% 
  filter(location_type == "outside") %>% 
  .[sf_cbgs,]

# palette
pm25_pal <- colorNumeric(
  palette = "RdYlGn",
  reverse = T,
  domain = c(
    sf_pm25_voronoi_cbg$PM25,
    sf_sensors$PM25
  )
)

leaflet() %>% 
  addProviderTiles(
    provider = providers$CartoDB.Positron
  ) %>% 
  addPolygons(
    data = sf_pm25_voronoi_cbg %>% 
      filter(GEOID != "060759804011"), #Farallon Islands 
    fillColor = ~pm25_pal(PM25),
    fillOpacity = .5,
    color = "white",
    weight = .5,
    label = ~PM25,
    highlightOptions = highlightOptions(
      weight = 2,
      opacity = 1
    )
  ) %>% 
  addCircleMarkers(
    data = sf_sensors,
    fillColor = ~pm25_pal(PM25),
    fillOpacity = 1,
    color = "black",
    weight = .5,
    radius = 5, 
    label = ~PM25
  ) %>% 
  addLegend(
    pal = pm25_pal,
    values = c(
      sf_pm25_voronoi_cbg$PM25,
      sf_sensors$PM25
    )
  )

```




grabbing longer data from february
```{r geographic equity}
# belmont -- change to your location here
belmont_boundary <- places("CA", cb = T) %>% 
  filter(NAME == "Belmont") %>% 
  st_transform(4326)

# quick visualization
mapview(belmont_boundary)

belmont_sensors <- bay_sensors_clean %>% 
  .[belmont_boundary, ]

# start <-  paste0("2022-02-14%2000:08:00")
# end <-  "2022-02-21%2000:08:00"

# create start and end dates
start <- as.Date("2022-02-01",format = "%Y-%m-%d")
end <- as.Date("2022-02-28",format = "%Y-%m-%d")

feb_date <- start

# create empty dataframe to populate final info
feb_data <- data.frame(
      matrix(
        ncol = 4,
        nrow = 0
      )
    )
    
    colnames(feb_data) <- c("date", "ID", "Location", "PM25")
feb_data[1,] <- NA
feb_data$date <- as.Date(feb_data$date)

# loop through all sensors throughout february
feb_belmont_sensor_data <- 
  1:nrow(belmont_sensors) %>% 
  map_dfr(function(row){
    
    print(paste0(row,", ", belmont_sensors[row, ]$sensor_index))
    
    while (feb_date <= end){
      print(feb_date)
      
      
      a1 <- read_csv(paste0(
    "https://api.thingspeak.com/channels/",
    belmont_sensors[row,]$primary_id_a,
    "/feeds.csv?api_key=",
    belmont_sensors[row,]$primary_key_a,
    "&average=1440&round=3&start=",feb_date,"%2000:08:00",
    "&end=", feb_date + 7, 
    "&timezone=America/Los_Angeles"
  ), show_col_types = F) %>% 
    set_names(c("created_at",
                "PM1.0_CF_1_ug/m3_A",
                "PM2.5_CF_1_ug/m3_A",
                "PM10.0_CF_1_ug/m3_A",
                "Uptime_Minutes_A",
                "RSSI_dbm_A",
                "Temperature_F_A",
                "Humidity_%_A",
                "PM2.5_CF_ATM_ug/m3_A"))
      
      combined <- a1 %>%
        transmute(
          date = as.Date(created_at),
          ID = as.numeric(belmont_sensors[row,]$sensor_index),
          Location = belmont_sensors[row,]$location_type,
          PM25 = 0.524*as.numeric(`PM2.5_CF_1_ug/m3_A`) - 0.0852*as.numeric(`Humidity_%_A`) + 5.72
          )
      
      
      feb_data <- rbind(feb_data, combined)
      
      feb_date <- feb_date + 7 
    }
    
    feb_data
    
  }
  
  
  
  ) 


# summarize to show dail PM2.5 indoor/outdoor data
feb_daily_belmont_data <- feb_belmont_sensor_data %>% 
  group_by(date, Location) %>% 
  summarize(
    PM25 = mean(PM25, na.rm = T)
  ) %>% 
  na.omit() %>% 
  filter(Location == "outside")

feb_daily_belmont_data$city = "Belmont"

feb_daily_belmont_data <- feb_daily_belmont_data[1:28,]


# dave your location data here

# raw data
saveRDS(feb_belmont_sensor_data, "feb_belmont_sensor_data.rds")

saveRDS(feb_daily_belmont_data, paste0(path_data,"feb_daily_belmont_data.rds"))
saveRDS(feb_daily_belmont_data, paste0(path,"feb_daily_belmont_data.rds"))
```

use casewhen to ID the week/visualize another way. 


Plotting PM2.5 over time
```{r}
feb_daily_belmont_data %>% 
  ggplot() +
  geom_line(
    aes(
      x = date,
      y = PM25,
      color = Location
    )
  )


```

```{r}
fc_sensor_data <- readRDS("C:/Users/mouse/OneDrive - Stanford/MS2/WinterQ/218Y/Hazards/fc_sensor_data.rds")
```

